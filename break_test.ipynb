{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "os.chdir(\"/home/jshenouda/break_test_llms\")  # Change to the actual subdirectory name\n",
    "from train_mnist import MLP\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from test_indep import generalized_robust_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupts cossine similarity by shifting weight around the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_mlp(model, D_mats= None):\n",
    "    \"\"\"Modify an MLP model by applying deep reparameterization ensuring network equivalence.\"\"\"\n",
    "    modified_model = MLP(model.model[0].in_features, \n",
    "                          [layer.out_features for layer in model.model if isinstance(layer, nn.Linear)][:-1], \n",
    "                          model.model[-1].out_features)\n",
    "    if D_mats is None:\n",
    "        # controls distortion to mess up cosine sim\n",
    "        lam = 5\n",
    "\n",
    "        # Generate the D_k matrices if non given\n",
    "        D_mats = []\n",
    "        # count number of ReLU layers\n",
    "        num_hidden = sum(1 for layer in model.model if isinstance(layer, nn.ReLU))\n",
    "        for layer in model.model:\n",
    "            if len(D_mats) == num_hidden:\n",
    "                break\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                max_exp = 30  # Limit exponent growth\n",
    "                i = torch.linspace(-max_exp, max_exp, layer.out_features)\n",
    "                D1_values = torch.exp(i)\n",
    "                D = torch.diag(D1_values)\n",
    "                # D = torch.diag(torch.tensor([lam**j for j in range(layer.out_features)])).to(torch.float)\n",
    "                D_mats.append(D)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for (orig_layer, new_layer) in zip(model.model, modified_model.model):\n",
    "            if isinstance(orig_layer, nn.Linear):\n",
    "                if i < model.affine_layers-1:\n",
    "                    if i == 0:\n",
    "                        new_layer.weight.data = torch.inverse(D_mats[0]) @ orig_layer.weight.data\n",
    "                        new_layer.bias.data = torch.inverse(D_mats[0]) @ orig_layer.bias.data\n",
    "                    else:\n",
    "                        new_layer.weight.data = torch.inverse(D_mats[i]) @ orig_layer.weight.data @ D_mats[i-1]\n",
    "                        new_layer.bias.data = torch.inverse(D_mats[i]) @ orig_layer.bias.data\n",
    "                else:\n",
    "                    # For the last linear layer\n",
    "                    new_layer.weight.data = orig_layer.weight.data @ D_mats[-1]\n",
    "                    new_layer.bias.data = orig_layer.bias.data\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    return modified_model, D_mats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28*28\n",
    "num_layers = 6\n",
    "hidden_dims = [100]*num_layers  # 6 hidden layers\n",
    "output_dim = 10\n",
    "\n",
    "trained_model = MLP(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Load the trained model\n",
    "trained_model.load_state_dict(torch.load(\"mnist_mlp_6_layers.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model\n",
    "modified_model, D_matrices = modify_mlp(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "test_data= datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "def ensure_models_equivalent(model1, model2, test_loader, device):\n",
    "    \"\"\"Ensure two models produce the same output for all 10,000 test MNIST samples.\"\"\"\n",
    "    model1.to(device)   \n",
    "    model2.to(device)\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            output1 = model1(data)\n",
    "            output2 = model2(data)\n",
    "            \n",
    "            dist = torch.linalg.norm(output1 - output2, ord='fro')**2\n",
    "    \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4379e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Ensure both models are equivalent\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(ensure_models_equivalent(trained_model, modified_model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each weight matrix compare cossine similarity between rows of original weigth matrix and modified weight matrix\n",
    "def compare_weights(model1, model2):\n",
    "    with torch.no_grad():\n",
    "        for (layer1, layer2) in zip(model1.model, model2.model):\n",
    "            if isinstance(layer1, nn.Linear):\n",
    "                cos_sim = nn.CosineSimilarity(dim=1)\n",
    "                sim = cos_sim(layer1.weight, layer2.weight)\n",
    "                print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 6.1892e-01, 1.4986e-01,\n",
      "        4.4569e-01, 2.0985e-01, 1.1936e-01, 2.5537e-02, 3.4244e-02, 8.9439e-03,\n",
      "        9.3881e-03, 1.2862e-03, 9.0915e-04, 1.8157e-03, 9.2772e-04, 4.3628e-04,\n",
      "        2.7113e-04, 3.3137e-05, 7.3358e-05, 1.2506e-05], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1712, 0.1039, 0.1735, 0.0946,\n",
      "        0.0752, 0.2200, 0.2370, 0.2763, 0.1783, 0.0958, 0.3006, 0.1357, 0.1554,\n",
      "        0.1140, 0.1321, 0.0992, 0.2283, 0.1885, 0.1207, 0.1535, 0.1776, 0.1704,\n",
      "        0.3468, 0.1439, 0.1843, 0.1165, 0.1776, 0.1832, 0.2189, 0.2273, 0.2678,\n",
      "        0.1393, 0.2963, 0.1317, 0.1670, 0.1350, 0.1188, 0.2722, 0.0976, 0.2165,\n",
      "        0.2406, 0.2327, 0.0840, 0.0690, 0.1525, 0.0991, 0.1927, 0.1611, 0.1138,\n",
      "        0.0878, 0.2158, 0.1539, 0.1343, 0.0841, 0.1704, 0.2096, 0.1419, 0.2127,\n",
      "        0.1312, 0.2102, 0.1985, 0.1289, 0.1300, 0.2782, 0.0633, 0.1897, 0.2035,\n",
      "        0.2122, 0.1692, 0.2750, 0.0969, 0.1755, 0.2547, 0.3023, 0.2323, 0.1113,\n",
      "        0.1825], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1635, 0.2650, 0.2451, 0.1742, 0.1631,\n",
      "        0.1848, 0.1824, 0.3131, 0.2784, 0.1674, 0.2279, 0.1861, 0.1339, 0.1469,\n",
      "        0.1345, 0.2291, 0.1213, 0.2169, 0.2319, 0.1993, 0.1775, 0.1820, 0.1679,\n",
      "        0.1823, 0.1822, 0.2753, 0.1510, 0.2681, 0.1344, 0.1333, 0.2344, 0.1531,\n",
      "        0.1575, 0.2514, 0.1829, 0.2670, 0.1357, 0.2071, 0.1347, 0.1690, 0.1805,\n",
      "        0.2081, 0.1354, 0.1828, 0.2414, 0.2302, 0.2187, 0.1414, 0.2529, 0.1273,\n",
      "        0.2155, 0.1926, 0.1331, 0.1966, 0.1997, 0.2968, 0.1971, 0.1462, 0.2418,\n",
      "        0.3194, 0.1796, 0.1427, 0.2050, 0.1612, 0.0863, 0.1847, 0.2038, 0.1680,\n",
      "        0.1058, 0.2289, 0.1477, 0.1758, 0.1372, 0.1925, 0.2479, 0.2493, 0.1196,\n",
      "        0.1808], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1707, 0.1118, 0.1377, 0.0784, 0.2713,\n",
      "        0.1323, 0.2009, 0.2505, 0.1950, 0.1023, 0.1807, 0.1526, 0.1353, 0.2484,\n",
      "        0.1984, 0.1915, 0.2200, 0.2420, 0.0949, 0.1589, 0.1672, 0.0989, 0.1014,\n",
      "        0.2182, 0.2272, 0.1632, 0.2874, 0.1063, 0.1897, 0.1169, 0.1494, 0.2083,\n",
      "        0.1568, 0.1280, 0.0979, 0.1537, 0.1338, 0.1652, 0.1613, 0.1285, 0.1574,\n",
      "        0.1509, 0.2060, 0.1968, 0.1414, 0.3214, 0.1765, 0.1350, 0.1704, 0.0960,\n",
      "        0.2153, 0.1207, 0.3358, 0.1775, 0.2208, 0.1583, 0.1717, 0.0782, 0.1022,\n",
      "        0.2418, 0.2541, 0.1268, 0.1891, 0.1381, 0.2612, 0.1201, 0.2098, 0.2010,\n",
      "        0.2043, 0.2793, 0.1809, 0.2349, 0.1248, 0.2073, 0.1172, 0.1307, 0.3111,\n",
      "        0.1627], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.1658, 0.1453, 0.2245, 0.1716, 0.2002,\n",
      "        0.1070, 0.2255, 0.1837, 0.1347, 0.1729, 0.2165, 0.1239, 0.3019, 0.1977,\n",
      "        0.1638, 0.3015, 0.1754, 0.2302, 0.2103, 0.1355, 0.1792, 0.1440, 0.1665,\n",
      "        0.2060, 0.1846, 0.1178, 0.1941, 0.2330, 0.1312, 0.0923, 0.1704, 0.1419,\n",
      "        0.1787, 0.2873, 0.1350, 0.1502, 0.1631, 0.1352, 0.0920, 0.2138, 0.1901,\n",
      "        0.1510, 0.1528, 0.1377, 0.1831, 0.2742, 0.2409, 0.1406, 0.1624, 0.1579,\n",
      "        0.1010, 0.2447, 0.3139, 0.2165, 0.1658, 0.1564, 0.1993, 0.1479, 0.1642,\n",
      "        0.1187, 0.1498, 0.1791, 0.1514, 0.2071, 0.2956, 0.1278, 0.3179, 0.2191,\n",
      "        0.1732, 0.1540, 0.1373, 0.1584, 0.1807, 0.2337, 0.1668, 0.1044, 0.1889,\n",
      "        0.2203], device='cuda:0')\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1728, 0.1455, 0.1816, 0.1224,\n",
      "        0.2591, 0.1428, 0.3395, 0.2389, 0.1588, 0.1825, 0.2520, 0.2618, 0.2014,\n",
      "        0.2102, 0.2064, 0.2270, 0.2595, 0.1391, 0.2171, 0.1926, 0.1427, 0.1423,\n",
      "        0.1364, 0.2604, 0.1742, 0.3110, 0.2831, 0.1785, 0.3187, 0.2538, 0.2077,\n",
      "        0.2597, 0.1335, 0.1691, 0.2991, 0.1607, 0.1662, 0.1298, 0.2494, 0.1221,\n",
      "        0.1958, 0.3066, 0.1782, 0.1637, 0.1715, 0.1030, 0.1550, 0.2421, 0.1836,\n",
      "        0.2002, 0.2522, 0.1683, 0.1624, 0.1556, 0.1843, 0.1578, 0.1156, 0.1373,\n",
      "        0.2170, 0.1867, 0.1457, 0.3031, 0.2910, 0.1835, 0.1802, 0.2128, 0.1986,\n",
      "        0.2501, 0.1095, 0.2073, 0.2545, 0.1880, 0.1736, 0.1995, 0.1753, 0.2530,\n",
      "        0.1513], device='cuda:0')\n",
      "tensor([0.2647, 0.2614, 0.1484, 0.1651, 0.1256, 0.3025, 0.2647, 0.1147, 0.2055,\n",
      "        0.1621], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "compare_weights(trained_model, modified_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dependent model that has been adversarially scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_match, trial 0: 0.2289572031211562\n",
      "Phi_match, trial 1: 0.3410480011046848\n",
      "Phi_match, trial 2: 0.4147488534122712\n",
      "Phi_match, trial 3: 0.5713855224247645\n",
      "Phi_match, trial 4: 0.29872463379453373\n",
      "Phi_match, trial 5: 0.33406733711285796\n",
      "Phi_match, trial 6: 0.8666473065817599\n",
      "Phi_match, trial 7: 0.21295422987530077\n",
      "Phi_match, trial 8: 0.32701425823197083\n",
      "Phi_match, trial 9: 0.33333348542169383\n",
      "Phi_match, trial 10: 0.5464159008987335\n",
      "Phi_match, trial 11: 0.00894365941600539\n",
      "Phi_match, trial 12: 0.805484996717724\n",
      "Phi_match, trial 13: 0.5364940193930473\n",
      "Phi_match, trial 14: 0.7280986799847264\n",
      "Phi_match, trial 15: 0.7630743291351696\n",
      "Phi_match, trial 16: 0.4630822719662432\n",
      "Phi_match, trial 17: 0.8112080513781876\n",
      "Phi_match, trial 18: 0.7032094898633872\n",
      "Phi_match, trial 19: 0.7555186675702286\n",
      "Phi_match, trial 20: 0.9309605926344972\n",
      "Phi_match, trial 21: 0.5405410569298903\n",
      "Phi_match, trial 22: 0.46049385474462534\n",
      "Phi_match, trial 23: 0.8312040705874487\n",
      "Phi_match, trial 24: 0.019012475523570438\n",
      "Phi_match, trial 25: 0.7678224628999732\n",
      "Phi_match, trial 26: 0.8115301270122948\n",
      "Phi_match, trial 27: 0.9816922026549151\n",
      "Phi_match, trial 28: 0.6066937517810307\n",
      "Phi_match, trial 29: 0.5410584117904459\n",
      "Phi_match, trial 30: 0.2771703684240734\n",
      "Phi_match, trial 31: 0.18361548955911733\n",
      "Phi_match, trial 32: 0.3970045788672917\n",
      "Phi_match, trial 33: 0.20896220404741617\n",
      "Phi_match, trial 34: 0.49404345313778475\n",
      "Phi_match, trial 35: 0.4725068822534303\n",
      "Phi_match, trial 36: 0.9992269445419186\n",
      "Phi_match, trial 37: 0.6900150083323318\n",
      "Phi_match, trial 38: 0.8242925260301242\n",
      "Phi_match, trial 39: 0.7084072863232079\n",
      "Phi_match, trial 40: 0.43285254832564346\n",
      "Phi_match, trial 41: 0.1652423961029592\n",
      "Phi_match, trial 42: 0.08073610876227666\n",
      "Phi_match, trial 43: 0.4450953509154745\n",
      "Phi_match, trial 44: 0.3312648292251019\n",
      "Phi_match, trial 45: 0.27984320069433755\n",
      "Phi_match, trial 46: 0.17469189249951578\n",
      "Phi_match, trial 47: 0.8071866216934362\n",
      "Phi_match, trial 48: 0.010651751083914585\n",
      "Phi_match, trial 49: 0.3913922980749267\n",
      "Phi_match, trial 50: 0.5755226272174799\n",
      "Phi_match, trial 51: 0.7370931802354228\n",
      "Phi_match, trial 52: 0.5080363696537549\n",
      "Phi_match, trial 53: 0.4245238125066906\n",
      "Phi_match, trial 54: 0.1821616583810608\n",
      "Phi_match, trial 55: 0.4689705956223742\n",
      "Phi_match, trial 56: 0.5994712429142988\n",
      "Phi_match, trial 57: 0.26836385436686816\n",
      "Phi_match, trial 58: 0.26519974265618806\n",
      "Phi_match, trial 59: 0.41775485326242445\n",
      "Phi_match, trial 60: 0.21860197069248555\n",
      "Phi_match, trial 61: 0.24407068588022196\n",
      "Phi_match, trial 62: 0.6587343328182601\n",
      "Phi_match, trial 63: 0.5966736752332529\n",
      "Phi_match, trial 64: 0.3501021729134124\n",
      "Phi_match, trial 65: 0.4819466731401162\n",
      "Phi_match, trial 66: 0.896393251613196\n",
      "Phi_match, trial 67: 0.46218791192933817\n",
      "Phi_match, trial 68: 0.02996906232648988\n",
      "Phi_match, trial 69: 0.3282571192944588\n",
      "Phi_match, trial 70: 0.7957637046602115\n",
      "Phi_match, trial 71: 0.4084754485239741\n",
      "Phi_match, trial 72: 0.9104655403014007\n",
      "Phi_match, trial 73: 0.3977819429722098\n",
      "Phi_match, trial 74: 0.5794661675690295\n",
      "Phi_match, trial 75: 0.41914384638543223\n",
      "Phi_match, trial 76: 0.31498643127914017\n",
      "Phi_match, trial 77: 0.6587343328182601\n",
      "Phi_match, trial 78: 0.10048683960770999\n",
      "Phi_match, trial 79: 0.08202233843069884\n",
      "Phi_match, trial 80: 0.4825134298085596\n",
      "Phi_match, trial 81: 0.984702402822203\n",
      "Phi_match, trial 82: 0.48114382961856017\n",
      "Phi_match, trial 83: 0.4224814493507667\n",
      "Phi_match, trial 84: 0.14662606276441892\n",
      "Phi_match, trial 85: 0.27685204806377284\n",
      "Phi_match, trial 86: 0.5525151298846523\n",
      "Phi_match, trial 87: 0.2999208362324459\n",
      "Phi_match, trial 88: 0.42773061087624076\n",
      "Phi_match, trial 89: 0.11713025148487988\n",
      "Phi_match, trial 90: 0.2896391342233249\n",
      "Phi_match, trial 91: 0.7692366664140499\n",
      "Phi_match, trial 92: 0.0658003953944224\n",
      "Phi_match, trial 93: 0.4644947918116502\n",
      "Phi_match, trial 94: 0.7114570890623034\n",
      "Phi_match, trial 95: 0.8704224324414215\n",
      "Phi_match, trial 96: 0.7968427410430308\n",
      "Phi_match, trial 97: 0.6533635273504941\n",
      "Phi_match, trial 98: 0.6675290658245749\n",
      "Phi_match, trial 99: 0.6470811140660913\n"
     ]
    }
   ],
   "source": [
    "# Run algo 5 to determine whether trained_model and modified_model are independent\n",
    "# low phi_match --> dependent\n",
    "# high phi_match --> independent\n",
    "\n",
    "## Low phi_match is < 10^{-10}\n",
    "## High phi_match is uniformly distributed on [0, 1]\n",
    "phi_matches = []\n",
    "num_trials = 100\n",
    "for i in range(num_trials):\n",
    "    phi_match = generalized_robust_test(trained_model, modified_model, 3)\n",
    "    print('Phi_match, trial {}: {}'.format(i,phi_match))\n",
    "    phi_matches.append(phi_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(phi_matches, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing true independent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28*28\n",
    "num_layers = 6\n",
    "hidden_dims = [100]*num_layers  # 6 hidden layers\n",
    "output_dim = 10\n",
    "\n",
    "indep_trained_model = MLP(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Load the trained model\n",
    "indep_trained_model.load_state_dict(torch.load(\"indep_mnist_mlp_6_layers.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_match, trial 0: 0.8985588268491083\n",
      "Phi_match, trial 1: 0.27470800871415135\n",
      "Phi_match, trial 2: 0.006900594453299491\n",
      "Phi_match, trial 3: 0.2796832837260512\n",
      "Phi_match, trial 4: 0.40011642250714674\n",
      "Phi_match, trial 5: 0.07698480650606387\n",
      "Phi_match, trial 6: 0.6261611214099749\n",
      "Phi_match, trial 7: 0.502458332053942\n",
      "Phi_match, trial 8: 0.41747717524869055\n",
      "Phi_match, trial 9: 0.5943309741454186\n",
      "Phi_match, trial 10: 0.7246972342594405\n",
      "Phi_match, trial 11: 0.4123475786253541\n",
      "Phi_match, trial 12: 0.448844459378128\n",
      "Phi_match, trial 13: 0.8392558400740983\n",
      "Phi_match, trial 14: 0.9971731668231982\n",
      "Phi_match, trial 15: 0.8615077651408801\n",
      "Phi_match, trial 16: 0.3995668136437166\n",
      "Phi_match, trial 17: 0.5941470909576421\n",
      "Phi_match, trial 18: 0.9012981595264135\n",
      "Phi_match, trial 19: 0.48964771968205145\n",
      "Phi_match, trial 20: 0.7009868232401905\n",
      "Phi_match, trial 21: 0.9973787830955839\n",
      "Phi_match, trial 22: 0.15125676757422146\n",
      "Phi_match, trial 23: 0.8569131464782558\n",
      "Phi_match, trial 24: 0.11897789496572919\n",
      "Phi_match, trial 25: 0.541810805509215\n",
      "Phi_match, trial 26: 0.15566804952493796\n",
      "Phi_match, trial 27: 0.3980564023803068\n",
      "Phi_match, trial 28: 0.5013709987621924\n",
      "Phi_match, trial 29: 0.07761245365915548\n",
      "Phi_match, trial 30: 0.029013118369916047\n",
      "Phi_match, trial 31: 0.9067763492481742\n",
      "Phi_match, trial 32: 0.3290724247089578\n",
      "Phi_match, trial 33: 0.4565908507897023\n",
      "Phi_match, trial 34: 0.7878752821302427\n",
      "Phi_match, trial 35: 0.9798045070171175\n",
      "Phi_match, trial 36: 0.7875298784097786\n",
      "Phi_match, trial 37: 0.4603527147530918\n",
      "Phi_match, trial 38: 0.889631109420162\n",
      "Phi_match, trial 39: 0.10453868002391853\n",
      "Phi_match, trial 40: 0.8929396063810875\n",
      "Phi_match, trial 41: 0.170757197066153\n",
      "Phi_match, trial 42: 0.1979451371867038\n",
      "Phi_match, trial 43: 0.4605409024984002\n",
      "Phi_match, trial 44: 0.1453671727564032\n",
      "Phi_match, trial 45: 0.6938997990992061\n",
      "Phi_match, trial 46: 0.7469251859135639\n",
      "Phi_match, trial 47: 0.0891075669848106\n",
      "Phi_match, trial 48: 0.9854210984750371\n",
      "Phi_match, trial 49: 0.08178570180926747\n",
      "Phi_match, trial 50: 0.4519408781148093\n",
      "Phi_match, trial 51: 0.13026077956149762\n",
      "Phi_match, trial 52: 0.7199568417076239\n",
      "Phi_match, trial 53: 0.3970502950480832\n",
      "Phi_match, trial 54: 0.434857832605411\n",
      "Phi_match, trial 55: 0.6705410980917179\n",
      "Phi_match, trial 56: 0.00725222146228055\n",
      "Phi_match, trial 57: 0.833717430950059\n",
      "Phi_match, trial 58: 0.543221144163012\n",
      "Phi_match, trial 59: 0.058112509640784404\n",
      "Phi_match, trial 60: 0.43313225444966896\n",
      "Phi_match, trial 61: 0.6311822913824581\n",
      "Phi_match, trial 62: 0.2676982347161321\n",
      "Phi_match, trial 63: 0.5779824400940693\n",
      "Phi_match, trial 64: 0.2508361627821003\n",
      "Phi_match, trial 65: 0.7417257571622062\n",
      "Phi_match, trial 66: 0.5089344117137542\n",
      "Phi_match, trial 67: 0.6597786545318667\n",
      "Phi_match, trial 68: 0.44064958318626535\n",
      "Phi_match, trial 69: 0.2518972849233767\n",
      "Phi_match, trial 70: 0.2770907718074922\n",
      "Phi_match, trial 71: 0.9157878767330168\n",
      "Phi_match, trial 72: 0.1273428246831556\n",
      "Phi_match, trial 73: 0.5249456535353618\n",
      "Phi_match, trial 74: 0.8441891954153906\n",
      "Phi_match, trial 75: 0.20793689244851477\n",
      "Phi_match, trial 76: 0.2565861304900203\n",
      "Phi_match, trial 77: 0.6812085923907508\n",
      "Phi_match, trial 78: 0.5292851203224181\n",
      "Phi_match, trial 79: 0.6662349129653182\n",
      "Phi_match, trial 80: 0.5273987863273358\n",
      "Phi_match, trial 81: 0.48997854481791114\n",
      "Phi_match, trial 82: 0.16467947095598223\n",
      "Phi_match, trial 83: 0.591248257619822\n",
      "Phi_match, trial 84: 0.029565625610467494\n",
      "Phi_match, trial 85: 0.15487019123855095\n",
      "Phi_match, trial 86: 0.2868819662413886\n",
      "Phi_match, trial 87: 0.44453339320253027\n",
      "Phi_match, trial 88: 0.4796800169434168\n",
      "Phi_match, trial 89: 0.6534948896611528\n",
      "Phi_match, trial 90: 0.06469609099320972\n",
      "Phi_match, trial 91: 0.6488425011528476\n",
      "Phi_match, trial 92: 0.6767455877712509\n",
      "Phi_match, trial 93: 0.974881139964671\n",
      "Phi_match, trial 94: 0.5273044533950303\n",
      "Phi_match, trial 95: 0.16622301867549472\n",
      "Phi_match, trial 96: 0.03795108596584751\n",
      "Phi_match, trial 97: 0.6904756016678018\n",
      "Phi_match, trial 98: 0.27407428961897473\n",
      "Phi_match, trial 99: 0.8399251731820978\n"
     ]
    }
   ],
   "source": [
    "# Run algo 5 to determine whether trained_model and modified_model are independent\n",
    "# low phi_match --> dependent\n",
    "# high phi_match --> independent\n",
    "\n",
    "## Low phi_match is < 10^{-10}\n",
    "## High phi_match is uniformly distributed on [0, 1]\n",
    "phi_matches = []\n",
    "num_trials = 100\n",
    "for i in range(num_trials):\n",
    "    phi_match = generalized_robust_test(trained_model, indep_trained_model, 3)\n",
    "    print('Phi_match, trial {}: {}'.format(i,phi_match))\n",
    "    phi_matches.append(phi_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(phi_matches, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the test with an exact copy of the trained model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28*28\n",
    "num_layers = 6\n",
    "hidden_dims = [100]*num_layers  # 6 hidden layers\n",
    "output_dim = 10\n",
    "\n",
    "trained_model_copy = MLP(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Load the trained model\n",
    "trained_model_copy.load_state_dict(torch.load(\"mnist_mlp_6_layers.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi_match, trial 0: 0.16132764918452447\n",
      "Phi_match, trial 1: 0.014443155741344027\n",
      "Phi_match, trial 2: 0.005018938548777552\n",
      "Phi_match, trial 3: 0.0019324570552650133\n",
      "Phi_match, trial 4: 0.0032628762843519565\n",
      "Phi_match, trial 5: 0.6399160548970081\n",
      "Phi_match, trial 6: 0.29757171025899987\n",
      "Phi_match, trial 7: 0.20024061897610346\n",
      "Phi_match, trial 8: 0.20077514528107665\n",
      "Phi_match, trial 9: 0.045529448804567774\n",
      "Phi_match, trial 10: 0.3737939518796801\n",
      "Phi_match, trial 11: 0.2100934261820594\n",
      "Phi_match, trial 12: 0.23072713435982273\n",
      "Phi_match, trial 13: 0.2437722640692539\n",
      "Phi_match, trial 14: 0.09916163322275728\n",
      "Phi_match, trial 15: 0.21371625044637388\n",
      "Phi_match, trial 16: 0.1735575833090266\n",
      "Phi_match, trial 17: 0.14977688202807526\n",
      "Phi_match, trial 18: 0.24545340661840775\n",
      "Phi_match, trial 19: 0.2053186846160171\n",
      "Phi_match, trial 20: 0.03962389302743541\n",
      "Phi_match, trial 21: 0.04068313367875209\n",
      "Phi_match, trial 22: 0.7090591513294418\n",
      "Phi_match, trial 23: 0.05407290143311161\n",
      "Phi_match, trial 24: 0.686992987483349\n",
      "Phi_match, trial 25: 0.08497650598016793\n",
      "Phi_match, trial 26: 0.0085908757363925\n",
      "Phi_match, trial 27: 0.7248558971296093\n",
      "Phi_match, trial 28: 0.7140478258894295\n",
      "Phi_match, trial 29: 0.17009178189487895\n",
      "Phi_match, trial 30: 0.09382564648560254\n",
      "Phi_match, trial 31: 0.18702466569286136\n",
      "Phi_match, trial 32: 0.01699504038370725\n",
      "Phi_match, trial 33: 0.0014021265443657782\n",
      "Phi_match, trial 34: 0.032361473935057394\n",
      "Phi_match, trial 35: 0.01916067692014345\n",
      "Phi_match, trial 36: 0.0017474950032100312\n",
      "Phi_match, trial 37: 0.3301034291823033\n",
      "Phi_match, trial 38: 0.8064677989946027\n",
      "Phi_match, trial 39: 0.2432504928782464\n",
      "Phi_match, trial 40: 0.43644457765636846\n",
      "Phi_match, trial 41: 0.006389777923792139\n",
      "Phi_match, trial 42: 0.001512444040649985\n",
      "Phi_match, trial 43: 0.12849454270885663\n",
      "Phi_match, trial 44: 0.0852386839469873\n",
      "Phi_match, trial 45: 0.5078945697576555\n",
      "Phi_match, trial 46: 0.6595611866734661\n",
      "Phi_match, trial 47: 0.14225135104542774\n",
      "Phi_match, trial 48: 0.6280914385260544\n",
      "Phi_match, trial 49: 0.05535833212742647\n",
      "Phi_match, trial 50: 0.3378326655794165\n",
      "Phi_match, trial 51: 0.013569559892749106\n",
      "Phi_match, trial 52: 0.7089777048824136\n",
      "Phi_match, trial 53: 0.3992005164957576\n",
      "Phi_match, trial 54: 0.18782672340254802\n",
      "Phi_match, trial 55: 0.2730460153982448\n",
      "Phi_match, trial 56: 0.46684996229953524\n",
      "Phi_match, trial 57: 0.3471182897084335\n",
      "Phi_match, trial 58: 0.9382235755475301\n",
      "Phi_match, trial 59: 0.050355874081493224\n",
      "Phi_match, trial 60: 0.03667554341854662\n",
      "Phi_match, trial 61: 0.06809960962966377\n",
      "Phi_match, trial 62: 0.09188934934905246\n",
      "Phi_match, trial 63: 0.000816664865572414\n",
      "Phi_match, trial 64: 0.5723624070339546\n",
      "Phi_match, trial 65: 0.12312352924059355\n",
      "Phi_match, trial 66: 0.42745156903062276\n",
      "Phi_match, trial 67: 0.14974905138191907\n",
      "Phi_match, trial 68: 0.04332440220116385\n",
      "Phi_match, trial 69: 0.3272712475281343\n",
      "Phi_match, trial 70: 0.42926597368162234\n",
      "Phi_match, trial 71: 0.436164489901404\n",
      "Phi_match, trial 72: 0.4465475752389698\n",
      "Phi_match, trial 73: 0.34178827785224297\n",
      "Phi_match, trial 74: 0.9860454497313736\n",
      "Phi_match, trial 75: 0.23549573781455946\n",
      "Phi_match, trial 76: 0.44584479669833754\n",
      "Phi_match, trial 77: 0.02440404193859591\n",
      "Phi_match, trial 78: 0.7674590831717787\n",
      "Phi_match, trial 79: 0.6740984276956912\n",
      "Phi_match, trial 80: 0.1592624118760929\n",
      "Phi_match, trial 81: 0.47741400753843144\n",
      "Phi_match, trial 82: 0.643416355702987\n",
      "Phi_match, trial 83: 0.057428126499233456\n"
     ]
    }
   ],
   "source": [
    "# Run algo 5 to determine whether trained_model and modified_model are independent\n",
    "# low phi_match --> dependent\n",
    "# high phi_match --> independent\n",
    "\n",
    "## Low phi_match is < 10^{-10}\n",
    "## High phi_match is uniformly distributed on [0, 1]\n",
    "phi_matches_copy = []\n",
    "num_trials = 100\n",
    "for i in range(num_trials):\n",
    "    phi_match = generalized_robust_test(trained_model, trained_model_copy, 3)\n",
    "    print('Phi_match, trial {}: {}'.format(i,phi_match))\n",
    "    phi_matches_copy.append(phi_match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
